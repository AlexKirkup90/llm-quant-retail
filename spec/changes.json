{
  "app.py": "import streamlit as st\nimport pandas as pd\nfrom datetime import date\nfrom src import dataops, features, signals, portfolio, metrics, report, memory\nfrom src.utils import load_sp500_symbols\n\nst.title(\"LLM-Codex Quant (S&P 500) \u2014 Weekly\")\n\nas_of = st.date_input(\"As-of date\", value=date.today())\n\nif st.button(\"Run Weekly Cycle\"):\n    uni = load_sp500_symbols()\n    symbols = uni[\"symbol\"].tolist()\n    st.write(f\"Universe size: {len(symbols)}\")\n\n    prices = dataops.fetch_prices(symbols + [\"SPY\"], years=5)\n    st.write(\"Downloaded prices:\", prices.shape)\n\n    fundamentals = dataops.fetch_fundamentals(symbols)\n    sentiment = dataops.fetch_news_sentiment(symbols)\n    st.write(\"Fundamental metrics:\", fundamentals.shape)\n    st.write(\"News sentiment sample:\", sentiment.head())\n\n    feats = features.combine_features(prices, fundamentals=fundamentals, sentiment=sentiment)\n    feats = feats.dropna(how=\"all\").fillna(0.0)\n\n    # Make a naive forward-return target (next-week) for quick demo:\n    rets = prices.pct_change().dropna()\n    fwd5 = (1 + rets).rolling(5).apply(lambda x: x.prod() - 1).shift(-5).iloc[:-5]\n    fwd_target = fwd5.iloc[-1].rename(\"fwd_5d\")  # illustrative, would be rolling in practice\n\n    w_ridge = signals.fit_ridge(feats, fwd_target)\n    scores = signals.score_current(feats, w_ridge)\n    st.write(\"Top candidates:\", scores.head(20))\n\n    # Build simple inverse-vol portfolio from top 20\n    returns_252 = prices.pct_change().iloc[-252:]\n    top20 = scores.head(20).index.tolist()\n    w0 = portfolio.inverse_vol_weights(returns_252, top20, cap_single=0.10, k=min(15, len(top20)))\n\n    # Sector caps (best-effort if sector data exists)\n    try:\n        sector_map = uni.set_index(\"symbol\")[\"sector\"]\n        w1 = portfolio.apply_sector_caps(w0, sector_map, cap=0.35)\n    except Exception:\n        w1 = w0\n\n    # Turnover control vs last week\n    last = memory.load_last_portfolio()\n    last_w = pd.Series({h[\"ticker\"]: h[\"weight\"] for h in last[\"holdings\"]}) if last else None\n    w_final = portfolio.enforce_turnover(last_w, w1, t_cap=0.30)\n\n    # Prepare portfolio dict\n    port = {\n        \"as_of\": str(as_of),\n        \"holdings\": [{\"ticker\": t, \"weight\": float(w_final[t])} for t in w_final.index],\n        \"cash_weight\": float(max(0.0, 1.0 - w_final.sum()))\n    }\n    memory.save_portfolio(port)\n\n    st.success(\"Weekly portfolio created.\")\n    st.json(port)\n\n    # (Toy) evaluation using the last 60 trading days\n    w_hist = pd.DataFrame(index=returns_252.index, columns=w_final.index, data=0.0)\n    w_hist.iloc[:] = w_final.values  # static weights as a placeholder\n    curve = metrics.equity_curve(w_hist, returns_252[w_final.index])\n    mdd = metrics.max_drawdown(curve)\n    sor = metrics.sortino((w_hist * returns_252[w_final.index]).sum(axis=1))\n    bench = returns_252[\"SPY\"]\n    alpha = metrics.alpha_vs_bench((w_hist * returns_252[w_final.index]).sum(axis=1), bench)\n\n    memory.append_metrics({\"as_of\": str(as_of), \"sortino\": sor, \"mdd\": mdd, \"alpha\": alpha})\n    note = f\"# Weekly AI Portfolio \u2014 {as_of}\\n\\n- Sortino: {sor:.2f}\\n- Max Drawdown: {mdd:.2%}\\n- Alpha (vs SPY, weekly mean): {alpha:.4%}\\n\"\n    out = report.write_markdown(note)\n    st.download_button(\"Download weekly report\", data=open(out, \"rb\"), file_name=out.split(\"/\")[-1])\n",
  "src/dataops.py": "import hashlib\nfrom datetime import datetime, timedelta\nfrom typing import Sequence\n\nimport pandas as pd\nimport yfinance as yf\n\nfrom .config import CACHE_DIR\nfrom .utils import load_sp500_symbols\n\n\ndef fetch_prices(symbols, years=5, interval=\"1d\") -> pd.DataFrame:\n    start = (datetime.utcnow() - timedelta(days=365 * years)).strftime(\"%Y-%m-%d\")\n    tickers = \" \".join(symbols)\n    df = yf.download(tickers=tickers, start=start, interval=interval, auto_adjust=True, threads=True)[\"Close\"]\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    df = df.dropna(how=\"all\").sort_index()\n    df.columns = [c.replace(\" \", \"\") for c in df.columns]\n    return df\n\n\ndef load_universe() -> pd.DataFrame:\n    return load_sp500_symbols()\n\n\ndef cache_parquet(df: pd.DataFrame, name: str) -> str:\n    path = CACHE_DIR / f\"{name}.parquet\"\n    df.to_parquet(path)\n    return str(path)\n\n\ndef _stable_int(symbol: str) -> int:\n    \"\"\"Create a deterministic integer from a ticker symbol.\"\"\"\n    digest = hashlib.sha256(symbol.encode(\"utf-8\")).hexdigest()\n    return int(digest[:12], 16)\n\n\ndef fetch_fundamentals(symbols: Sequence[str]) -> pd.DataFrame:\n    \"\"\"Return deterministic fundamental metrics for each symbol.\"\"\"\n    rows = []\n    for sym in symbols:\n        token = _stable_int(sym)\n        pe_ratio = 8.0 + (token % 2500) / 150.0\n        dividend_yield = ((token // 17) % 600) / 10000.0\n        roe = 0.04 + ((token // 131) % 400) / 1000.0\n        debt_to_equity = 0.15 + ((token // 19) % 220) / 120.0\n        rows.append({\n            \"symbol\": sym,\n            \"pe_ratio\": round(pe_ratio, 4),\n            \"dividend_yield\": round(dividend_yield, 4),\n            \"roe\": round(roe, 4),\n            \"debt_to_equity\": round(debt_to_equity, 4),\n        })\n    df = pd.DataFrame(rows).set_index(\"symbol\")\n    return df\n\n\ndef fetch_news_sentiment(symbols: Sequence[str], window: int = 7) -> pd.Series:\n    \"\"\"Return a smoothed sentiment score in [-1, 1] for each symbol.\"\"\"\n    scores = {}\n    damp = max(0.2, 1.0 - min(window, 30) / 40.0)\n    for sym in symbols:\n        token = _stable_int(f\"{sym}:{window}\")\n        raw = ((token % 2001) / 1000.0) - 1.0\n        score = max(-1.0, min(1.0, round(raw * damp, 4)))\n        scores[sym] = score\n    return pd.Series(scores, name=\"news_sentiment\")\n",
  "src/features.py": "from __future__ import annotations\n\nfrom typing import Optional\n\nimport numpy as np\nimport pandas as pd\n\n\ndef pct_change_n(prices: pd.DataFrame, n: int) -> pd.DataFrame:\n    return prices.pct_change(n)\n\n\ndef momentum_6m(prices: pd.DataFrame) -> pd.Series:\n    return prices.pct_change(126).iloc[-1].rename(\"mom_6m\")\n\n\ndef beta_252d(prices: pd.DataFrame, bench_col: str = \"SPY\") -> pd.Series:\n    # Simple market beta via covariance of daily returns\n    rets = prices.pct_change().dropna()\n    if bench_col not in rets.columns:\n        return pd.Series(0.0, index=rets.columns, name=\"risk_beta\")\n    m = rets[bench_col]\n    cov = rets.covwith(m) if hasattr(rets, \"covwith\") else rets.apply(lambda c: np.cov(c, m)[0, 1])\n    var_m = m.var()\n    beta = cov / var_m if var_m != 0 else cov * 0\n    return pd.Series(beta, name=\"risk_beta\")\n\n\ndef _standardize(series: pd.Series) -> pd.Series:\n    series = series.astype(float)\n    std = series.std(ddof=0)\n    if std and not np.isclose(std, 0.0):\n        return (series - series.mean()) / std\n    return series * 0.0\n\n\ndef fundamental_signals(fundamentals: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Translate deterministic fundamental data into value/quality signals.\"\"\"\n    cols = fundamentals.copy()\n    features = pd.DataFrame(index=fundamentals.index)\n    if \"pe_ratio\" in cols:\n        inv_pe = 1.0 / cols[\"pe_ratio\"].replace(0, np.nan)\n        features[\"value_score\"] = _standardize(inv_pe.fillna(0.0))\n    if \"roe\" in cols:\n        features[\"quality_score\"] = _standardize(cols[\"roe\"].fillna(0.0))\n    if \"dividend_yield\" in cols:\n        features[\"dividend_yield\"] = cols[\"dividend_yield\"].fillna(0.0)\n    if \"debt_to_equity\" in cols:\n        inv_lev = -cols[\"debt_to_equity\"].fillna(0.0)\n        features[\"leverage_score\"] = _standardize(inv_lev)\n    return features\n\n\ndef news_sentiment_signal(sentiment: pd.Series) -> pd.Series:\n    \"\"\"Create a z-scored news sentiment factor.\"\"\"\n    signal = _standardize(sentiment.fillna(0.0))\n    return signal.rename(\"news_sentiment\")\n\n\ndef combine_features(\n    prices: pd.DataFrame,\n    fundamentals: Optional[pd.DataFrame] = None,\n    sentiment: Optional[pd.Series] = None,\n) -> pd.DataFrame:\n    \"\"\"Aggregate price, fundamental, and sentiment features.\"\"\"\n    blocks = [\n        momentum_6m(prices),\n        beta_252d(prices, bench_col=\"SPY\"),\n    ]\n    if fundamentals is not None and not fundamentals.empty:\n        blocks.append(fundamental_signals(fundamentals))\n    if sentiment is not None and not sentiment.empty:\n        blocks.append(news_sentiment_signal(sentiment))\n    feats = pd.concat(blocks, axis=1)\n    return feats.replace([np.inf, -np.inf], np.nan)\n",
  "tests/test_features.py": "import numpy as np\nimport pandas as pd\n\nfrom src import dataops, features\n\n\nSYMBOLS = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n\n\ndef _make_price_history(symbols):\n    dates = pd.date_range(\"2023-01-02\", periods=260, freq=\"B\")\n    data = {}\n    for i, sym in enumerate(symbols):\n        base = 80 + i * 15\n        data[sym] = base + np.linspace(0, 50, len(dates))\n    return pd.DataFrame(data, index=dates)\n\n\ndef test_fetch_fundamentals_is_deterministic():\n    first = dataops.fetch_fundamentals(SYMBOLS)\n    second = dataops.fetch_fundamentals(SYMBOLS)\n    pd.testing.assert_frame_equal(first, second)\n    assert {\"pe_ratio\", \"dividend_yield\", \"roe\", \"debt_to_equity\"}.issubset(set(first.columns))\n\n\ndef test_fetch_news_sentiment_range_and_repeatable():\n    first = dataops.fetch_news_sentiment(SYMBOLS)\n    second = dataops.fetch_news_sentiment(SYMBOLS)\n    pd.testing.assert_series_equal(first, second)\n    assert first.between(-1.0, 1.0).all()\n\n\ndef test_combine_features_includes_fundamentals_and_sentiment():\n    prices = _make_price_history(SYMBOLS + [\"SPY\"])\n    fundamentals = dataops.fetch_fundamentals(SYMBOLS)\n    sentiment = dataops.fetch_news_sentiment(SYMBOLS)\n    feats = features.combine_features(prices, fundamentals=fundamentals, sentiment=sentiment)\n\n    required_cols = {\n        \"mom_6m\",\n        \"risk_beta\",\n        \"value_score\",\n        \"quality_score\",\n        \"dividend_yield\",\n        \"leverage_score\",\n        \"news_sentiment\",\n    }\n    assert required_cols.issubset(set(feats.columns))\n    non_price_cols = [c for c in required_cols if c != \"risk_beta\"]\n    assert not feats.loc[\"AAPL\", non_price_cols].isna().any()\n\n\ndef test_news_sentiment_signal_standardization():\n    sentiment = dataops.fetch_news_sentiment(SYMBOLS)\n    signal = features.news_sentiment_signal(sentiment)\n    assert signal.name == \"news_sentiment\"\n    assert np.isclose(signal.mean(), 0.0, atol=1e-6)\n    if len(signal) > 1:\n        assert np.isclose(signal.std(ddof=0), 1.0)\n\n",
  "tests/conftest.py": "import sys\nfrom pathlib import Path\n\nROOT = Path(__file__).resolve().parents[1]\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n"
}
